---
title: "ProbCom"
runtime: shiny
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r libraries and data, include=FALSE}
library(flexdashboard)
library(knitr)
library(DiagrammeR)
library(tidyverse)
library(googlesheets4)
library(plotly)
library(shiny)
library(formattable)
library(stringr)
library(colorspace)

# Get latest data; note: cannot connect to Google in application. Must save files locally.
# data <- read_sheet("https://docs.google.com/spreadsheets/d/1IyHoJpZiOV6_0soAgWqEoDCK4Uh9OnvxxaL0aRryN5M/edit#gid=0", sheet = "Data Extraction")
# data <- data %>% drop_na(Source)
# data.findings <- read_sheet("https://docs.google.com/spreadsheets/d/1IyHoJpZiOV6_0soAgWqEoDCK4Uh9OnvxxaL0aRryN5M/edit#gid=0", sheet = "Findings / Recs Spreadsheet")
# saveRDS(data, "data_extraction.Rds")
# saveRDS(data.findings, "data_findings.Rds")

data <- readRDS("data_extraction.Rds")
data.findings <- readRDS("data_findings.Rds")

data <- data %>% 
  mutate(ID = paste0(`Article ID`, `Study ID`)) %>%
  rename(
    cod_1 = 'Coder',
    cod_2 = 'Coder 2',
    int_1 = 'Int.', 
    int_2 = 'Int. 2', 
    ext_1 = 'Ext.', 
    ext_2 = 'Ext. 2', 
    dom_1 = 'Dom.',
    dom_2 = 'Dom. 2') %>% 
  mutate_at(vars(int_1:dom_2), ~ifelse(. == 0, 1, .)) %>% 
  mutate(int = (int_1 + int_2) / 2, 
         ext = (ext_1 + ext_2) / 2,
         dom = (dom_1 + dom_2) / 2)
```


```{css, echo = FALSE}
# This code chunk is necessary to make sure that the gauges on the "Core Findings" page are sized dynamically.
<style> .html-widget.gauge {
  height: 100%; 
}

.html-widget.gauge svg {
  height: 100%; 
  margin-top: 10px;
  margin-bottom: 40px;
} </style>
```

Executive Summary
=========================================

## Executive Summary

<center> **Living Systematic Review of Research on Communicating Probability Information** </center> 

**Motivation**

Probabilistic forecast information is rapidly proliferating, injecting in a new wave of uncertainty into the forecast and warning process. Most scientists agree that this is a positive development, but incorporating probability information into risk communication can be challenging, as probabilities are notoriously difficult to communicate effectively to lay audiences. What does the research literature say about the best way to include probability information in risk communication? What is the evidence base for different communication practices? This project endeavors to address these questions by conducting a living review of relevant research from past studies and new studies as they become available.

**Systematic Review**

A systematic review is a type of literature review that uses a transparent and replicable methodology to identify relevant research from past studies, evaluate results from those studies, and synthesize findings both qualitatively and quantitatively. Historically, systematic reviews have been static; they synthesize the literature at a point in time and become out-of-date almost as soon as they are complete. To prevent this, living systematic reviews are beginning to replace static reviews. Living reviews follow the same steps but are updated as new research becomes available.

Systematic reviews generally include some combination of the following steps:

1. Define the study domain
2. Search for and identify relevant studies
3. Extract key topics, questions, methods, and findings from relevant studies
4. Evaluate the quality of relevant studies
5. Analyze and combine the studies to identify common topics, questions, methods, and findings

This review includes two more steps:

6. Assess common findings to develop recommendations to assist in communicating uncertainty and probabilities
7. Develop a living platform that incorporates new studies and relevant findings into the review as they become available

**Steps in This Review**

***1. Define the study domain.*** We focus on research studies that directly examine the impact of probability information on protective action decision making, intentions, and behaviors. Most of the studies in the review focus on the “best” or most effective way to communicate probability information. For example, they address questions like: are people more likely to take protective action when probability information is given verbally or numerically? Though extremely important, we do not include studies that indirectly examine these relationships by way of implication or suggestion. For example, we do not include studies that explore the relationship between numeracy and risk perceptions, which may have important implications for how people use probability information when making decisions.

***2. Search for and identify relevant studies.*** Consistent with best practices, we use three iterative methods to search for and identify relevant studies: (1) electronic search databases; (2) past literature reviews; and (3) citation chains. We use three electronic search databases (ProQuest, Web of Science, and EBSCO Academic Search Elite). At the start of the review, the electronic search databases gave us 1,559 potentially relevant studies; 725 of the studies were unique across the three databases. Of the 725 unique studies, 29 met the inclusion criteria---(1) they fit within the study domain (see above); (2) they report on new findings from a new research project (e.g., not a literature review, essay, or workshop report); and (3) they use a reasonably generalizable, transparent, and replicable methodology to conduct the research. Past literature reviews (12 of them) gave us 37 more studies that met the inclusion criteria and citation chains ("backwards" and "forwards") gave us 255 more studies that met the criteria, bring the beginning set of relevant studies to 327. Because this is a living systematic review, it is important to reiterate that this is only the beginning of the review. We plan to repeat these phases every few months to make sure that we are including the most up-to-date research. See *Bibliographic Archive* for a complete list of the articles in the review.

***3. Extract key topics, questions, methods, and findings from relevant studies.*** we carefully scan all relevant studies, extract key information, and store it in an electronic spreadsheet. In addition to basic bibliographic information, we note relevant research questions, independent (treatment) and outcome variables, research methodologies (i.e., survey experiment), information about research subjects, domains of study (i.e., weather, health, etc.), and primary findings.

***4. Evaluate the quality of relevant studies.*** We use three indicators of validity to assess quality: (1) external validity (are the results generalizable to the population of interest?); (2) internal validity (are we sure that variation in x causes variation in y?); and (3) domain validity (how relevant is the study domain to weather hazards and forecasting?). Each dimension is independently given a score by two researchers on a three point scale (1 = low; 2 = medium; 3 = high). We use the mean value of these scores to measure validity along each dimension and the overall validity of each study.

***5. Analyze and combine the studies to identify common topics, questions, methods, and findings.*** We use the database of key topics, questions, methods, and findings from each study to identify commonalities across the relevant studies. Broadly, most of the studies that are currently in the review ask one of two research questions: (1) How does probability information impact risk comprehension? (2) How does probability information impact protective action decisions, intentions, and/or behaviors? A significant majority of the studies use survey research and quantitative analysis (statistics) to address these questions. Many of the studies employ survey experiments to compare the impact of one type of probability information (e.g., a slight chance of rain) to the impact of an alternative way of the present the same information (e.g., a 20% chance of rain). We were able to identify 5 primary research topics and 14 secondary topics. See *State of the Literature* for more information on these topics. Across these topics, we were able to identify more than 100 unique research findings. See *Core Findings* for a complete list of these findings.

***6. Assess common findings to develop recommendations to assist in communicating uncertainty and probabilities.*** This is the most difficult and subjective step in the review. In this step, we work as a team to translate core findings into actionable recommendations. This is challenging because we have to decide which of the core findings are certain and relevant enough to support a recommendation. Relevancy is the primary challenge. Many studies in this review advance basic science but do not relate the findings to specific communication challenges. While valuable, it can be difficult to translate these findings into actionable advice for risk communicators. In addition, many studies in the review provide actionable advice on how to communicate probability in domains like healthcare. Again, the insight from these studies can be extremely valuable but difficult to translate into actionable advice for risk communicators who work in extreme weather/climate domains. This is where the subjectivity enters into the process. We pick the core findings that we believe are most relevant to forecasters.

***7. Develop a living platform that incorporates new studies and relevant findings into the review as they become available.*** Looks like you made it to the *ProbCom* platform---take a look and let us know if you have any questions!

Bibliographic Archive 
=========================================

**This page contains the complete bibliographic archive of all the studies we examined for this reivew. Click on a study in the table below to view the abstract, the subjective internal, external, and domain validity scores given to each study, and a link to the study's DOI page.**

Column 
-----------------------------------------------------------------------

### Study Name {.no-title .no-padding data-height=40}

<span style="color: #4682B4;"> **Study:** </span> `r renderText(select_react() %>% pull(var = Citation))` </font> 

### Study Details {.no-title data-height=175}

<span style="color: #4682B4;"> **Abstract:** </span> `r renderText(select_react() %>% pull(var = Abstract))`

<span style="color: #4682B4;"> **Internal Validity:** </span> `r renderText(select_react() %>% pull(var = int))`/3 | 
<span style="color: #4682B4;"> **External Validity:** </span> `r renderText(select_react() %>% pull(var = ext))`/3 | 
<span style="color: #4682B4;"> **Domain Validity:** </span> `r renderText(select_react() %>% pull(var = dom))`/3

<!-- Makes the DOI a hyperlink -->
<span style="color: #4682B4;"> **DOI:** </span> `r renderUI({a(select_react() %>% pull(var = DOI), href = paste0("https://doi.org/", select_react() %>% pull(var = DOI)))})`

### Bibliographic Archive {.no-title}
```{r}
# Renders the full list of studies. Also acts as the input for the Study Details table above.
font.size <- "10pt"
DT::datatable(data %>% select(Study, 
                              `Summary of Findings`, 
                              `Cited in Report`:`Not Cited`, 
                              `Internal Validity` = int, 
                              `External Validity` = ext, 
                              `Domain Validity` = dom) %>% 
                mutate_all(~str_replace_na(., "")) %>% 
                mutate(`Topic(s)` = paste(`Cited in Report`, `Cited in Report II`, `Cited in Report III`, `Not Cited`, sep = "; ")) %>% 
                mutate(`Topic(s)` = str_replace(`Topic(s)`, "; ; ; ", "")) %>%
                mutate(`Topic(s)` = str_replace(`Topic(s)`, "; ; ", "")) %>% 
                select(-c(`Cited in Report`:`Not Cited`)),
              filter = "top",
              selection = "single",
              rownames = FALSE,
              style = "bootstrap",
              class = "compact",
              options = list(dom = "Brtip", 
                             initComplete = htmlwidgets::JS("function(settings, json) {", 
                                                            paste0("$(this.api().table().container()).css({'font-size': '", 
                                                                   font.size, "'});"),"}")), # governs text size
              elementId = 'table1')

# This adds a new variable that indexes the position of each study in the dataset as it appears in the datatable. This is so that we can match the study up to the row number returned by input$table1_row_last_clicked later.

data <- data %>% mutate(tableNumber = c(1:nrow(data)))

# This creates the reactive version of our dataframe, w/ only the columns we want displayed. The if / else statement is there so that the default text is displayed before the user clicks a study on the datatable.

# select_react <- reactive({
# 
#   if(is.null(input$table1_row_last_clicked)){
#     
#     # This is the dataframe that is returned when input$table1_row_last_clicked = NA (on page load, before clicking the table)
#     data.frame(Study = "Click on one of the studies below to learn more!", 
#                Abstract = "None", 
#                DOI = "None", 
#                int = "0", 
#                ext = "0", 
#                dom = "0", 
#                stringsAsFactors = FALSE)
#     
#   } else {
#     
#   data %>%
#       filter(tableNumber == input$table1_row_last_clicked) %>%
#       select(Study, Abstract, DOI, int, ext, dom) %>% 
#       mutate(DOI = paste0("https://doi.org/", DOI))
#       
#   }
# })

# I usually try to populate things with the first observation to show readers what it looks like.

select_react <- reactive({

  if(
    
    is.null(input$table1_row_last_clicked)){
    data %>%
      filter(tableNumber == 1) %>%
      select(Study, Citation = `Full Citation`, Abstract, DOI, int, ext, dom)

  } else {

  data %>%
      filter(tableNumber == input$table1_row_last_clicked) %>%
      select(Study, Citation = `Full Citation`, Abstract, DOI, int, ext, dom)
  }
})
```

State of the Literature {.storyboard}
=========================================

**This page summarizes the state of the literature by plotting the percentage and mean validity of studies that address 5 primary and 14 secondary topics that are common in the literature. While this list of topics is likely to grow as the review continues, an examination of the relative frequency and validity of each topic provides valuable information about the *quantity* and *quality* of evidence we are able to identify in each topic area at a given point in time.**

### Percentage of studies that address primary topics of relevance.

```{r}
main_topics <- data %>% 
  select(ID = `Article ID`, `Cited in Report`:`Not Cited`) %>% 
  distinct(ID, .keep_all = TRUE) %>% 
  pivot_longer(`Cited in Report`:`Not Cited`) %>% 
  drop_na(value) %>% mutate(
    topic = case_when(
      value %in% c("Understanding Probability Information", 
                   "Probabilistic vs. Deterministic Information") ~ "(a) Public Understanding and Use of Prob. Info. in Decision Making",
      value %in% c("Numeric Translations of Words and Phrases", 
                   "Verbal Directionality and Reference Points", 
                   "Severity and Probability Conflation", 
                   "Choosing Words and Phrases") ~ "(b) Communicating Prob. Info. Using Words and Phrases",
      value %in% c("Percentages", "Frequencies", 
                   "Reference Class Ambiguity", 
                   "Numeric Directionality and Reference Points") ~ "(c) Communicating Prob. Info. Using Numbers",
      value %in% c("Non-Weather Visualizations", 
                   "Weather Visualizations", 
                   "General Visualization Advice", "") ~ "(d) Communicating Prob. Info. Using Visualizations",
      value %in% c("Communicating to a Heterogeneous Population") ~ "(e) Communicating Prob. Info. to a Heterogeneous Population")) %>% 
  filter(value != "Visualizations Intro")

main_topics$topic <- factor(main_topics$topic)
main_topics$topic <- factor(main_topics$topic, levels = rev(levels(main_topics$topic)))

main_freq_plot <- main_topics %>% 
  group_by(topic) %>% 
  summarise(n = n()) %>%
  drop_na() %>% 
  mutate(p = n / sum(n)) %>% 
  ggplot(., aes(y = topic, x = p, fill = topic, text = paste0(round(p * 100), "%"))) +
  geom_bar(stat = "identity") +
  scale_x_continuous(labels = scales::percent, limits = c(0, 0.3)) + 
  labs(x = "Studies in the Review") +
  theme_bw(base_size = 16) +
  theme(axis.title.y = element_blank()) +
  guides(fill = FALSE) +
  scale_fill_manual(values = rev(qualitative_hcl(5))) +
  theme(legend.position = 'none')

renderPlotly({
  ggplotly(main_freq_plot, tooltip = c("text"))
  })
```

### Percentage of studies within each primary topic that address secondary topics of relevance.

```{r}
secondary_topics <- data %>% 
  select(ID = `Article ID`, `Cited in Report`:`Not Cited`) %>% 
  distinct(ID, .keep_all = TRUE) %>% 
  pivot_longer(`Cited in Report`:`Not Cited`) %>% 
  drop_na(value) %>% 
  mutate(
    topic = case_when(
      value %in% c("Understanding Probability Information", 
                   "Probabilistic vs. Deterministic Information") ~ "(a) Public Understanding and Use of Prob. Info. in Decision Making",
      value %in% c("Numeric Translations of Words and Phrases", 
                   "Verbal Directionality and Reference Points", 
                   "Severity and Probability Conflation", 
                   "Choosing Words and Phrases") ~ "(b) Communicating Prob. Info. Using Words and Phrases",
      value %in% c("Percentages", 
                   "Frequencies", 
                   "Reference Class Ambiguity", 
                   "Numeric Directionality and Reference Points") ~ "(c) Communicating Prob. Info. Using Numbers",
      value %in% c("Non-Weather Visualizations", 
                   "Weather Visualizations", 
                   "General Visualization Advice", "") ~ "(d) Communicating Prob. Info. Using Visualizations",
      value %in% c("Communicating to a Heterogeneous Population") ~ "(e) Communicating Prob. Info. to a Heterogeneous Population")) %>% 
  mutate(sub_topic = case_when(
    value %in% c("Understanding Probability Information") ~ "(1) Understanding Probability Information", 
    value %in% c("Probabilistic vs. Deterministic Information") ~ "(2) Probabilistic vs. Deterministic Information",
    value %in% c("Numeric Translations of Words and Phrases") ~ "(1) Numeric Translations of Words and Phrases", 
    value %in% c("Verbal Directionality and Reference Points") ~ "(2) Directionality and Reference Points", 
    value %in% c("Severity and Probability Conflation") ~ "(3) Severity and Probability Conflation", 
    value %in% c("Choosing Words and Phrases") ~ "(4) Choosing Words and Phrases",
    value %in% c("Percentages") ~ "(1) Probabilities as Percentages", 
    value %in% c("Frequencies") ~ "(2) Probabilities as Frequencies", 
    value %in% c("Reference Class Ambiguity") ~ "(3) Reference Class Ambiguity", 
    value %in% c("Numeric Directionality and Reference Points") ~ "(4) Directionality and Reference Points",
    value %in% c("Non-Weather Visualizations") ~ "(1) Visualizations in Non-Weather Domains",
    value %in% c("Weather Visualizations") ~ "(2) Visualizations in Weather Domains",
    value %in% c("General Visualization Advice") ~ "(3) General Visualization Advice")) %>% 
  filter(value != "Visualizations Intro")

secondary_topics$topic <- factor(secondary_topics$topic)
secondary_topics$sub_topic <- factor(secondary_topics$sub_topic)
secondary_topics$sub_topic <- factor(secondary_topics$sub_topic, levels = rev(levels(secondary_topics$sub_topic)))

secondary_freq_plot <- secondary_topics %>% 
  group_by(topic, sub_topic) %>% 
  summarise(n = n()) %>%
  drop_na() %>% 
  mutate(p = n / sum(n)) %>% 
  ggplot(., aes(y = sub_topic, x = p, fill = topic, text = paste0(round(p * 100), "%"))) +
  geom_bar(stat = "identity") +
  scale_x_continuous(labels = scales::percent, limits = c(0, 0.7)) + 
  labs(x = "Studies in the Review") +
  theme_bw(base_size = 16) +
  theme(axis.title.y = element_blank()) +
  guides(fill = FALSE) +
  facet_wrap(~topic, scales = "free_y", nrow = 4) +
  scale_fill_manual(values = qualitative_hcl(5)[1:4]) +
  theme(legend.position = 'none')

renderPlotly({
  ggplotly(secondary_freq_plot, tooltip = c("text"))
  })
```

### Mean validity of studies that address primary topics of relevance.

```{r}
validity <- data %>% 
  select(ID = `Article ID`, int, ext, dom, `Cited in Report`, `Cited in Report II`, `Cited in Report III`, `Not Cited`) %>% 
  distinct(ID, .keep_all = TRUE) %>% 
  pivot_longer(`Cited in Report`:`Not Cited`) %>% 
  drop_na(value) %>% 
  mutate(
    topic = case_when(
      value %in% c("Understanding Probability Information", 
                   "Probabilistic vs. Deterministic Information") ~ "(a) Public Understanding and Use of Prob. Info. in Decision Making",
      value %in% c("Numeric Translations of Words and Phrases", 
                   "Verbal Directionality and Reference Points", 
                   "Severity and Probability Conflation", 
                   "Choosing Words and Phrases") ~ "(b) Communicating Prob. Info. Using Words and Phrases",
      value %in% c("Percentages", 
                   "Frequencies", 
                   "Reference Class Ambiguity", 
                   "Numeric Directionality and Reference Points") ~ "(c) Communicating Prob. Info. Using Numbers",
      value %in% c("Non-Weather Visualizations", 
                   "Weather Visualizations", 
                   "General Visualization Advice", "") ~ "(d) Communicating Prob. Info. Using Visualizations",
      value %in% c("Communicating to a Heterogeneous Population") ~ "(e) Communicating Prob. Info. to a Heterogeneous Population")) %>% 
  mutate(topic = factor(topic, levels = c("(e) Communicating Prob. Info. to a Heterogeneous Population", 
                                          "(d) Communicating Prob. Info. Using Visualizations",
                                          "(c) Communicating Prob. Info. Using Numbers",
                                          "(b) Communicating Prob. Info. Using Words and Phrases",
                                          "(a) Public Understanding and Use of Prob. Info. in Decision Making"))) %>% 
  mutate(sub_topic = case_when(
    value %in% c("Understanding Probability Information") ~ "(1) Understanding\nProbability\nInformation", 
    value %in% c("Probabilistic vs. Deterministic Information") ~ "(2) Probabilistic vs.\nDeterministic Information",
    value %in% c("Numeric Translations of Words and Phrases") ~ "(1) Numeric Translations\nof Words and Phrases", 
    value %in% c("Verbal Directionality and Reference Points") ~ "(2) Directionality and Reference Points", 
    value %in% c("Severity and Probability Conflation") ~ "(3) Severity and\nProbability Conflation", 
    value %in% c("Choosing Words and Phrases") ~ "(4) Choosing Words\nand Phrases",
    value %in% c("Percentages") ~ "(1) Probabilities\nas Percentages", 
    value %in% c("Frequencies") ~ "(2) Probabilities\nas Frequencies", 
    value %in% c("Reference Class Ambiguity") ~ "(3) Reference Class Ambiguity", 
    value %in% c("Numeric Directionality and Reference Points") ~ "(4) Directionality and\nReference Points",
    value %in% c("Non-Weather Visualizations") ~ "(1) Visualizations in\nNon-Weather Domains",
    value %in% c("Weather Visualizations") ~ "(2) Visualizations\nin Weather Domains",
    value %in% c("General Visualization Advice") ~ "(3) General Visualization\nAdvice")) %>% 
  filter(value != "Visualizations Intro")
  
means <- validity %>% 
  summarise(int = mean(int, na.rm = TRUE), ext = mean(ext, na.rm = TRUE), dom = mean(dom, na.rm = TRUE)) 
  
primary_valid_plot <- validity %>%
  group_by(topic) %>% 
  summarise(int = mean(int, na.rm = TRUE), ext = mean(ext, na.rm = TRUE), dom = mean(dom, na.rm = TRUE)) %>% 
  drop_na() %>% 
  mutate(ave = (int + ext + dom) / 3) %>% 
  ggplot(., aes(x = int, y = ext, size = dom, color = topic, 
                text = paste('Topic: ', topic,
                             '<br>Internal Validity:', round(int, 2), 
                             '<br>External Validity:', round(ext, 2),
                             '<br>Domain Validity:', round(dom, 2)))) + 
  geom_vline(xintercept = means$int, linetype = "dashed", alpha = 0.3) +
  geom_hline(yintercept = means$ext, linetype = "dashed", alpha = 0.3) +
  geom_point(alpha = 0.5) +
  labs(x = "Internal Validity (Causality)\n", 
       y = "\nExternal Validity (Generalizability)", 
       caption = "Sizes of the points indicate mean domain validity") +
  theme_bw(base_size = 15) +
  guides(color = FALSE, size = FALSE) +
  scale_size(range = c(10, 25)) +
  scale_color_manual(values = rev(qualitative_hcl(5))) +
  theme(legend.position = 'none')

renderPlotly({
  ggplotly(primary_valid_plot, tooltip = c("text")) %>% 
    layout(margin = list(b = 50, l = 50))
  })
```

### Mean validity of studies within each primary topic that address secondary topics or relevance.

```{r}
secondary_valid_plot <- validity %>%
  group_by(topic, sub_topic) %>% 
  summarise(int = mean(int, na.rm = TRUE), ext = mean(ext, na.rm = TRUE), dom = mean(dom, na.rm = TRUE)) %>% 
  drop_na() %>% 
  mutate(topic = factor(topic, levels = rev(c("(e) Communicating Prob. Info. to a Heterogeneous Population", 
                                              "(d) Communicating Prob. Info. Using Visualizations",
                                              "(c) Communicating Prob. Info. Using Numbers",
                                              "(b) Communicating Prob. Info. Using Words and Phrases",
                                              "(a) Public Understanding and Use of Prob. Info. in Decision Making")), 
         labels = rev(c("(e) Communicating Prob. Info. to a Heterogeneous Population", 
                        "(d) Communicating Prob. Info. Using Visualizations",
                        "(c) Communicating Prob. Info. Using Numbers",
                        "(b) Communicating Prob. Info. Using Words and Phrases",
                        "(a) Public Understanding and Use of Prob. Info. in Decision Making")))) %>% 
  ggplot(., aes(x = int, y = ext, size = dom, color = topic, 
                text = paste('Topic: ', sub_topic,
                             '<br>Internal Validity:', round(int, 2), 
                             '<br>External Validity:', round(ext, 2),
                             '<br>Domain Validity:', round(dom, 2)))) + 
  geom_vline(xintercept = means$int, linetype = "dashed", alpha = 0.3) +
  geom_hline(yintercept = means$ext, linetype = "dashed", alpha = 0.3) +
  geom_point(alpha = 0.5) +
  labs(x = "Internal Validity (Causality)", 
       y = "External Validity (Generalizability)", 
       caption = "Sizes of the points indicate mean domain validity") +
  theme_bw(base_size = 15) +
  guides(color = FALSE, size = FALSE) +
  scale_size(range = c(10 / 2, 25 / 2)) +
  facet_wrap(~topic) +
  scale_color_manual(values = qualitative_hcl(5)[1:4]) +
  theme(legend.position = 'none')

renderPlotly({
  ggplotly(secondary_valid_plot, tooltip = c("text")) %>% 
    layout(margin = list(b = 50, l = 100))
  })
```


Core Findings {data-orientation=rows}
=========================================

**This page contains a complete list of the "core findings" we identified from among the materials in our systematic review. This list includes any finding that either 1) is identified and replicated consistently across multiple high-quality studies, 2) is identified by at least one study of extremely high quality, or 3) has easily identifiable potential utility for end-users of this review. As a result, some of these findings have less supporting evidence than others. Click on any of the core findings in the table below to view the supporting studies and their associated (subjective) internal, external, and domain validity scores.**

Row {data-height=100}
-----------------------------------------

### Finding {.no-title}
```{r}
renderText({
  finding_react() %>%
    pull(var = Recomendation)
})

```

Row {data-height=300}
-------------------------------------------

### Supporting Studies
```{r}
# Using renderTable() would be simpler and cleaner looking than a datatable, but I couldn't think of a way to get the DOI to display as a link without it 

# renderTable({
# 
# data %>%
#   filter(str_detect(toString(finding_react() %>% pull(var = 'Studies Cited')), data$`Full ID`)) %>%
#   mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) </a>")) %>%
#   select(Study, Link)
#         
# })

renderDataTable({

data %>%
  filter(str_detect(toString(finding_react() %>% pull(var = 'Studies Cited')), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '250px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))

```


### Average Internal Validity
```{r}
renderGauge({
  temp <- data %>%
  filter(str_detect(toString(finding_react() %>% pull(var = 'Studies Cited')), data$`Full ID`)) %>%
  select(int, ext, dom) %>%
  summarise_all(mean)

  # I made all of the gauges go from 0-3 instead of from 1-3 because I think portaying 1 as absolute zero on the gauge implies that the study has zero credibility, which is not the case
  # I also think this might help us avoid the appearance of judging anyone's study as not credible or worthless, which might understandbly be offensive and isn't our intent
gauge(round(temp$int, 2), min = 0, max = 3, gaugeSectors(success = c(2.5, 3), warning = c(1.5, 2.5), danger = c(0, 1.5)))
}) 
```

### Average External Validity
```{r}
renderGauge({
  temp <- data %>%
  filter(str_detect(toString(finding_react() %>% pull(var = 'Studies Cited')), data$`Full ID`)) %>%
  select(int, ext, dom) %>%
  summarise_all(mean)
  
gauge(round(temp$ext, 2), min = 0, max = 3, gaugeSectors(success = c(2.5, 3), warning = c(1.5, 2.5), danger = c(0, 1.5)))
}) 
```

### Average Domain Validity
```{r}
renderGauge({
  temp <- data %>%
  filter(str_detect(toString(finding_react() %>% pull(var = 'Studies Cited')), data$`Full ID`)) %>%
  select(int, ext, dom) %>%
  summarise_all(mean)
  
gauge(round(temp$dom, 2), min = 0, max = 3, gaugeSectors(success = c(2.5, 3), warning = c(1.5, 2.5), danger = c(0, 1.5)))
}) 
```


Row
-----------------------------------------

### Complete List of Core Findings

```{r}

data.findings <- data.findings %>% mutate(tableNumber = c(1:nrow(data.findings)))

data.findings %>%
  select(Recomendation, Topic) %>%
  DT::datatable(., filter = "top",
              selection = "single",
              rownames = FALSE,
              style = "bootstrap",
              class = "compact",
              options = list(dom = "Brtip", 
                             initComplete = htmlwidgets::JS("function(settings, json) {", 
                                                            paste0("$(this.api().table().container()).css({'font-size': '", 
                                                                   font.size, "'});"),"}")), # governs text size
              elementId = 'findingTable')

finding_react <- reactive({

  if(
    
    is.null(input$findingTable_row_last_clicked)){
    data.findings %>%
      filter(tableNumber == 1) 

  } else {

  data.findings %>%
      filter(tableNumber == input$findingTable_row_last_clicked) 
  }
})

```


Practical Recommendations {.storyboard}
=========================================

**This page provides a list of recommendations to forecasters. This is very challenging because we have to decide which of the core findings are certain and relevant enough to support a recommendation. While we have extensive experience working with forecasters, we cannot know or define everything that might be relevant. We therefore urge visitors to carefully examine core findings on their own to see if there might be something of relevance that we are missing in the list of recommendations.** 

### 1. Use probability information in lieu of deterministic information.

<font size=3.5px>

**Recommendation #1:** Use probability information in lieu of deterministic information.

**Example:** 

- **Replace**: These storms will cause heavy downpours and flooding.
- **With**: There is an extremely high (90%) chance that these storms will cause heavy downpours and flooding.


**Example Studies**: <a href = "https://doi.org/10.1037/a0025185">Joslyn & LeClerc (2012)</a> and <a href = "https://doi.org/10.1037/xap0000165">Grounds & Joslyn (2018)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf1_studies <- data.findings %>%
  filter(ID == "124" | ID == "187" | ID == "196") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf1_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** Does the public actually understand, use, and benefit from probability information, or are they better off with deterministic statements? Some forecasters express a desire to "boil down" complex probability information to a deterministic point forecast for fear of confusing members of the public (Pappenberger et al. 2013). However, the evidence in this review suggests quite strongly that those fears are unfounded. Nearly all of the studies we review indicate that people make better decisions, have higher trust in information, and/or display a greater understanding of forecast information when shown a probabilistic forecast instead of a deterministic one (Ash et al. 2014; Bolton and Katok 2018; Grounds and Joslyn 2018; Grounds et al. 2017; Joslyn and LeClerc 2012; Joslyn and LeClerc 2016; Joslyn and Demnitz 2019; Joslyn et al. 2007; LeClerc and Joslyn 2012; Marimo et al. 2015; Miran et al. 2018; Nadav-Greenberg and Joslyn 2009; Roulston and Kaplan 2009; Roulston et al. 2006; Joslyn and Grounds 2015). The majority of these studies are firmly situated in the context of weather; however, it is important to note that both experts and the public sometimes have difficulty interpreting probability information, and different ways of communicating risk can lead to variation in understanding (Bramwell et al. 2006). Taken together, the studies in this review indicate a very strong and consistent pattern of results throughout the literature -- simple probabilistic forecasts outperform deterministic ones in almost all situations and by almost all metrics. This does not mean that the average forecast end-user is a competent statistician; in fact, many of these studies emphasize the need to make probabilistic forecasts as straightforward and easy to understand as possible in order to avoid “information overload” (Durbach and Stewart 2011). It is also important to note that these findings refer to probability information beyond a general acknowledgement of epistemological uncertainty (e.g. “this forecast is based on estimates; it is impossible to ever know for sure what will happen”), as these types of overly broad statements can undermine trust in forecasts (Howe et al. 2019). This research should, however, reassure those who worry that the public will be confused by anything other than a deterministic forecast. 


### 2. Use probability ranges (predictive intervals) to emphasize uncertainty when point estimates are not available or appropriate; wide ranges indicate more uncertainty.

<font size=3.5px>

**Recommendation #2:** Use probability ranges (predictive intervals) to emphasize uncertainty when point estimates are not available or appropriate; wide ranges indicate more uncertainty. 

**Example:** 

- **Replace**: The forecast is rapidly evolving, but there is a slight (15%) chance that we will see more than 10 inches of snow in the metro area tomorrow morning.
- **With**: The forecast is rapidly evolving, but there is a slight (10% to 20%) chance that we will see more than 10 inches of snow in the metro area tomorrow morning.


**Example Studies**: <a href = "https://doi.org/10.1155/2017/3932565">Grounds et al (2017)</a> and <a href = "https://doi.org/10.1175/WCAS-D-18-0136.1">Løhre et al. (2019)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf2_studies <- data.findings %>%
  filter(ID == "170" | ID == "171" | ID == "194" | ID == "116") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf2_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** If a point estimate like "30% chance" or "3 inches of rain" is unavailable or inappropriate, a confidence interval / range estimate like "20-30% chance" or "2.5-3.5 inches" is often an effective way of harnessing the benefits of providing probabilistic information to audiences. When using confidence intervals in communications, it is important to note the following: first, the size of a confidence interval can influence how people interpret a forecast - people seem to implicitly understand smaller confidence intervals to mean that a forecast is more technologically advanced and more certain (Teigen, Løhre, & Hohle 2018). Second, though confidence intervals are usually meant to denote that probabilities are normally distributed around a mean, most likely value, a plurality of people understand confidence intervals to mean that all values within the range were equally likely, an interpretation which is often incorrect. Clarifying how confidence intervals should be interpreted could help to offset this misunderstanding (Dieckmann et al 2015).

### 3. Include numeric translations next to words / phrases that indicate probability information.

<font size=3.5px>

**Recommendation #3:** Include numeric translations next to words / phrases that indicate probability information.

**Example:** 

- **Replace**: Severe thunderstorms are possible this evening.
- **With**: With: Severe thunderstorms are possible (20% to 30% chance) this evening.


**Example Studies**: <a href = "https://doi.org/10.1038/nclimate2194">Budescu et al. (2014)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf3_studies <- data.findings %>%
  filter(ID == "119" | ID == "120" | ID == "121") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf3_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** There is strong evidence that risk communicators should always include a numeric “translation” for any verbal probability expressions used, and that translation should appear directly in or next to the verbal expression itself  (Carey et al. 2018; Connelly and Knurth 1998; Dorval et al. 2013; Fortin et al. 2001; Hill et al. 2010; Zabini et al. 2015; Wintle et al. 2019). For example, a verbal expression like “severe thunderstorms are possible this evening” would be more effectively rephrased as “severe thunderstorms are possible (20% to 30% chance) this evening” (Budescu et al. 2014). Explicit statements of the upper and lower bound (e.g. 0-33%) implied by an expression (e.g. “likely” or “unlikely”) improve accuracy of interpretation vs. a statement alone (Harris et al. 2017). This is important not only because it helps people to correctly interpret the meaning of a forecast, but also because people generally prefer mixed formats (e.g. a numeric probability and a verbal probability expression together, or a number and a visualization) to singular ones (Carey et al. 2018; Connelly and Knurth 1998; Dorval et al. 2013; Fortin et al. 2001; Hill et al. 2010; Sink 1995; Zabini et al. 2015). Members of the public are able to demonstrate basic understanding of probabilistic forecasts; however, uncertainty is best communicated with a range of estimates rather than single points and through combined use of numeric and verbal expressions to meet the needs of heterogeneous audiences (Kox et al. 2015). Translations and numerical probabilities can sometimes lead to misinterpretation due to a number of factors related to both forecasters and audiences, such as use of correct terms, preferences, and numeracy (Sink 1995). Furthermore, translations are important because less numerate people tend to focus on narrative evidence when evaluating risk communications (the context, their perceptions regarding the likelihood of comparable events, etc.), while more numerate people tend to focus on the numeric probability of the risk (Budescu et al. 2009; Dieckmann et al. 2009; Budescu et al. 2012; Juanchich et al 2013; Mandel 2015).


### 4. If comprehension is especially important, use numeric probabilities alone or first (before words/phrases). 

<font size=3.5px>

**Recommendation #4:** If comprehension is especially important, use numeric probabilities alone or first (before words/phrases). 

**Example:** 

- **Replace**: Severe thunderstorms are possible (20% to 30% chance) this evening.
- **With**: There is a 20% to 30% chance of thunderstorms this evening.


**Example Studies**: <a href = "https://doi.org/10.1002/bdm.2072">Jenkins et al. (2019)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf4_studies <- data.findings %>%
   filter(ID == "119" | ID == "120" | ID == "121" | ID == "122") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf4_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** In addition to the findings supporting Recommendation #3, there is also evidence that numeric expressions of probability are better suited for communicating very sensitive or unlikely risks. In scenarios where underestimating risks could have disastrous consequences, it may be better to provide a number first, then use the verbal expression as a translation (opposite to the way the IPCC reports “translate” their uncertainty communications, for example) in order to minimize the “extremity effect” (Dilla & Stone 1997; Jenkins, Harris, & Lark 2018, Jenkins Harris, & Lark 2019; Patt & Dessai 2005; Windschitl et al. 2017). Purely verbal expressions of risk should generally be avoided, especially when the risk is particularly severe or the information is particularly critical for people to hear and understand. If for some reason you must choose between providing purely verbal or purely numeric information, numeric information should be prioritized because it is interpreted more consistently. There is also some evidence that people tend to be more comfortable with and trusting of purely numeric information as opposed to purely verbal information, and that purely verbal statements often lead people to overestimate risks (Budescu, Weinberg, & Wallsten 1988; Gurmankin et al. 2004; Knapp, Raynor, Woolf et. al. 2009; P. Knapp, Raynor, & Berry 2004).

### 5. When using words and phrases to communicate probability information, include rank adjectives (like low, medium, and high) to indicate the magnitude of the probability; this is especially important if numeric translations are not available.

<font size=3.5px>

**Recommendation #5:** When using words and phrases to communicate probability information, include rank adjectives (like low, medium, and high) to indicate the magnitude of the probability; this is especially important if numeric translations are not available.

**Example:** 

- **Replace**: There is a chance of snow and ice this morning along I-75.
- **With**: There is a low/medium/high chance of snow and ice this morning along I-75.


**Example Studies**: <a href = "https://doi.org/10.15191/nwajom.2020.0805">Lenhardt et al. (2020)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf5_studies <- data.findings %>%
   filter()

renderDataTable({

data %>%
  filter(str_detect(toString(cf5_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)

}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** 

- 

### 6. Use probability (percentage) formats when possible; frequency (fraction) formats can be effective, but they can also generate confusion.

<font size=3.5px>

**Recommendation #6:** Use probability (percentage) formats when possible; frequency (fraction) formats can be effective, but they can also generate confusion.

**Example:** 

- **Replace**: There is a 1 in 10 chance that this storm will produce a tornado.
- **With**: There is a 10% chance that this storm will produce a tornado.


**Example Studies**: <a href = "https://doi.org/10.1177/0272989X08315246">Cuite et al. (2008)</a> and <a href = "https://doi.org/10.1002/met.121">Joslyn & Nichols (2009)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf6_studies <- data.findings %>%
   filter(ID == "131" | ID == "132" | ID == "133" | ID == "134") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf6_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** Numeric probabilities are most commonly expressed as a percentage (e.g. “a 30% chance of rain”) or as a frequency (e.g. “a 3 in 10 chance of rain”). In general, the use of probability (percentage) formats has been observed to improve the accuracy of risk comprehension and encourage protective action over the use of verbal probability statements alone (Fuller et al. 2001; Fuller et al. 2002; Koehler 2001). Based on this, and on some of the findings of studies included in this review suggesting that frequency formats are less consistently understood, we recommend sticking with percentage formats (e.g. "30% chance") unless you have a particular reason to use a frequency format instead. Some evidence suggests, however, that when comparing between probability and frequency formats, there are few consistent and significant benefits to one over the other  (Hendrickx et al. 1989; Joslyn et al. 2009i; Neace et al. 2008; Knapp et al. 2016; Evans et al. 2000; Ruiz et al. 2013; Strathie et al. 2017). This research suggests that different circumstances call for different formats: advantageous use of frequency and percentage formats depends on the given task at hand and the context of the risk (Cuite et al. 2008; Knapp et al. 2009 ; Sinayev et al. 2015; Wallsten et al. 1986). 


### 7. When using frequency (fraction) formats, use 1 in X formats in place of X and NX formats.

<font size=3.5px>

**Recommendation #7:** When using frequency (fraction) formats, use 1 in X formats in place of X and NX formats.

**Example:** 

- **Replace**: Recent models indicate that there is a 20 in 100 chance that this storm will cause significant storm surge in the New Orleans area.
- **With**: Recent models indicate that there is a 1 in 5 chance that this storm will cause significant storm surge in the New Orleans area.


**Example Studies**: <a href = "https://doi.org/10.1177/0272989X11403490">Pighin et al. (2011)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf7_studies <- data.findings %>%
   filter(ID == "135") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf7_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** Frequency formats, which present probabilistic information as a “1 in X” and “X in NX “ chance, have been found to influence risk comprehension in a number of ways. For example, Pighin, et al. (2015) assessed the effects of format ("1 in X" or "N in NX") on the interpretations of risk information. They observed that individuals had elevated perceptions of risk when shown the “1 in X” format as compared to the “N in NX format”. Interestingly, this was still true despite no observed effect on comprehension (Pighin et al. 2015). Oudhoff and Timmermans (2015) examined format and graphic effects on decisions to engage in risk-laden activities. They noted that the “1-in-X” format yielded higher perceived likelihoods and appeared to be the easiest format to interpret; however, graphs primarily affect perceptions of likelihood among people with lower numeracy (Oudhoff & Timmermans 2015). Denes-Raj, Epstein, and Cole (1995) investigated the effects of using a “1 in X” format compared to “N in NX” format in order to better understand how ratio bias plays a role in decision making. Their research suggested that although ratio bias is common, it is not ubiquitous across different situations (Denes-Raj, Epstein & Cole 1995). 

### 8. Include information about the reference class when using probability information.

<font size=3.5px>

**Recommendation #8:** Include information about the reference class when using probability information. 

**Example:** 

- **Replace**: There is a low chance of tornadoes in the Oklahoma City metro area tomorrow afternoon and evening.
- **With**: There is a low (2%) chance of tornadoes in the Oklahoma City metro area tomorrow afternoon and evening; on 1 in 50 days like today, there will be a tornado within 25 miles of your location.


**Example Studies**: <a href = "https://doi.org/10.1111/j.1539-6924.2005.00608.x">Gigerenzer et. al. (2005)</a> and <a href = "https://doi.org/10.1080/20445911.2018.1553884">Juanchich & Sirota (2018)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf8_studies <- data.findings %>%
   filter(ID == "133" | ID == "153") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf8_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** Many of the studies included in this review suggest that, often, people have more trouble discerning the events that a probabilistic forecast refers to than they do understanding the probability itself. For instance, Evans et al. (2000) observe that formats, whether frequencies or percentages, have little effect on understanding, unless they are also presented in a way that “facilitated construction of a set inclusion mental model” (p. 197). Gigerenzer et al. (2005) argue that one way to provide such a definition is through the inclusion of reference class, or the class of events to which a probability refers. Rather than simply stating, “There is a 30% chance of rain tomorrow,” a forecast that includes reference class would be written, “There is a 30% chance of rain on days like tomorrow. This means that on 3 out of 10 days like tomorrow, it will rain” (Gigerenzer et al. 2005). Juanchich and Sirota (2018) find that specifying the reference class can increase correct interpretation by reducing misunderstanding and ambiguity in the way forecasts are presented. Neace et al. (2008) present evidence that supports using frequency formats to reduce errors, they also demonstrated that when controlling for reference class, this effect largely disappears, leaving little difference between frequency-based and probability-based formats. In short, don't assume audiences know what the word "rain" refers to in a statement like "there is a 30% chance of rain" (Will it rain 30% of the time? In 30% of my area? Is there a 30% chance of any rain falling at all, or do you mean a substantial rainfall?).


### 9. Be aware of “directionality” when using probability information; positive frames can promote comprehension by encouraging people to focus on the events that are most likely to happen, whereas negative frames can promote risk aversion by encouraging people to focus on the possibility of negative events, even if they are unlikely.

<font size=3.5px>

**Recommendation #9:** Be aware of “directionality” when using probability information; positive frames can promote comprehension by encouraging people to focus on the events that are most likely to happen, whereas negative frames can promote risk aversion by encouraging people to focus on the possibility of negative events, even if they are unlikely. 

**Example:** 

- **Replace**: There is a high (90%) chance of sunny skies today.
- **With**: There is a low (10%) chance of freezing drizzle today.


**Example Studies**: <a href = "https://doi.org/10.1080/17470218.2016.1225779">Honda & Yamagishi (2017)</a> and <a href = "https://doi.org/10.1006/obhd.1999.2857">Teigen & Brun (2003)</a>

<br>
**All Relevant / Supporting Studies:** </font>
```{r}
cf9_studies <- data.findings %>%
  filter(ID == "107") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf9_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** "Directionality" refers to whether a statement emphasizes the chance that something will not happen (e.g. "it is likely that the hurricane will miss our town") or the chance that something will happen (e.g. "it is unlikely that the hurricane will hit our town"). Findings from these studies suggest that forecasters should be mindful of these concepts when crafting verbal probability statements, as they can have unintended consequences on interpretation. It should be noted that there is no universal "best" choice to use when it comes to directionality and contextual factors can affect understanding, highlighting the ability for forecasters to accidentally imply that their forecasts are higher or lower than intended, thereby indirectly influencing how people interpret the communication. Generally, positive statements seem to draw attention to the possibility of an event happening and cause people to interpret such statements as more likely, while negative statements tend to have the opposite effect, promoting risk aversion by encouraging people to focus on the possibility of negative events, even if they are unlikely (Honda and Yamagishi 2006; 2009; 2017; McKenzie and Nelson 2003; Teigen and Brun 1995; 1999; 2000; 2003, Wallsten et al. 1986; Budescu et al. 2003).

### 10. When possible, include probability information in forecast visualizations.

<font size=3.5px>

**Recommendation #10:** When possible, include probability information in forecast visualizations. 

**Example:** 

- **Replace**: Maps showing deterministic warning boxes/polygons.
- **With**: Maps showing probabilistic information; for example: probability grids (FACETs); Potential Storm Surge Flooding map (NHC).


**Example Studies**: <a href = "https://doi.org/10.1175/WCAS-D-18-0094.1">Gerst et al. (2020)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf10_studies <- data.findings %>%
   filter(ID == "191" | ID == "209") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf10_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** Visualizations often provide an effective way to communicate probability information to groups who may have difficulty with probabilities expressed as numbers or words, even if for no other reason than because people want them and, subjectively, find them useful (Johnson and Slovic 1995; 1998). Use of visuals has also been shown to be more effective in communicating probability information with younger audiences (Ulph et al. 2009), and less numerate audiences (Okan et al. 2015), making them a crucial tool for risk communicators in any domain. In the domain of weather, probabilistic visualizations often come in the form of maps; the studies in this review suggest that people understand basic probability information about forecasts when presented with a map (Wu et al. 2014). Gerst et al. (2020) find that using simplified maps (e.g., legends, contour lines, white space) can improve overall understanding of probability information. Color and size-based visualizations allow for quicker but less thought-out decisions, while texture and icon-based depictions require more time and deliberation (Cheong et al. 2019; Seipel and Lim 2017; Leitner and Buttenfield 2000; Miran et al. 2017; Tak and Toet 2014.; Miran et al. 2016; Retchless and Brewer 2016; Sherman-Morris et al. 2015). In addition to colors, track lines have been found to increase levels of concern among members of the public with little effect on the interpretation of probability information (Meyer et al. 2013; Newman and Scholl 2012; Padilla et al. 2017; Ruginski et al. 2016; Van Pelt et al. 2015; Wu et al 2014). 



### 11. Use visualizations to increase comprehension of probability information; icon arrays and ensemble plots can be especially effective when teaching people how to interpret probability information. Note: this might not be appropriate immediately before or during high impact events.

<font size=3.5px>

**Recommendation #11:** Use visualizations to increase comprehension of probability information; icon arrays and ensemble plots can be especially effective when teaching people how to interpret probability information. Note: this might not be appropriate immediately before or during high impact events.

**Example:** 

- **Replace**: Models indicate that there is an 80% to 90% chance that hurricane force winds will affect Miami, FL in the next 5 days.
- **With**: 


**Example Studies**: <a href = "https://doi.org/10.1177/1473871618807121">Toet et al. (2019)</a> and <a href = "https://doi.org/10.1002/bdm.1797">Garcia-Retamero & Cokely (2014)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
cf11_studies <- data.findings %>%
   filter(ID == "207" | ID == "208" | ID == "212") 

renderDataTable({

data %>%
  filter(str_detect(toString(cf11_studies$'Studies Cited'), data$`Full ID`)) %>%
  mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
  select(Study, Link)
  
}, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
                   list(title = ""),
                   list(title = "")
                 )))
```

***

**Notes:** In addition to maps, other types of visualizations have been used to improve understanding of probability information in weather forecasts, including ensemble plots (Toet et al. 2019) and interactive formats (Hogarth and Soyer 2015; Natter and Berry 2005). For example, the visualization of a confidence interval can influence how people interpret a forecast. People understand smaller confidence intervals to mean that a forecast is more technologically advanced and more certain (Teigen et al. 2018). Additionally, predictive interval graphics can encourage protective action (S. Joslyn, Nemec, and Savelli 2013). Use of visualizations, however, can often depend on the purpose of communication. In some instances, the use of deterministic visualizations can increase protective action, while the use of probabilistic visualizations can better communicate changes in risk (Ash et al. 2014; Baker 1995; Marimo et al. 2015). 


### 12. Pay attention to the audience when using probability information; most people are able to grasp basic probability information, but a lot depends on numeracy and experience.

<font size=3.5px>

**Recommendation #12:** Pay attention to the audience when using probability information; most people are able to grasp basic probability information, but a lot depends on numeracy and experience.

**Example Studies**: <a href = "https://doi.org/10.1111/disa.12293">Wernstedt et al. (2018)</a> and <a href = "https://doi.org/10.1111/j.1539-6924.2009.01279.x">Dieckmann et al. (2009)</a>

<br>
**All Relevant / Supporting Studies:** </font>

```{r}
# cf12_studies <- data.findings %>%
#    filter(ID == "")
# 
# renderDataTable({
# 
# data %>%
#   filter(str_detect(toString(cf12_studies$'Studies Cited'), data$`Full ID`)) %>%
#   mutate(Link = paste0('<a href = "https://doi.org/', DOI, '">Link to Article</a>')) %>%
#   select(Study, Link)
# 
# }, escape = FALSE, options = list(scrollY = '500px', paging = FALSE, ordering = FALSE, searching = FALSE, dom = "t", columns = list(
#                    list(title = ""),
#                    list(title = "")
#                  )))
```

***

**Notes:** Many of the studies in the review include findings that, while important, are overly specific or difficult to generalize and use for forecasters. The general consensus of these findings, though, is clear: efforts to communicate probability information must also consider the heterogeneous nature of audiences and the different contexts and biases they entail. For instance, when it comes to both members of the public and experts, individuals sometimes have difficulty accurately interpreting forecasts that include probability information due to a number of different factors, such as context (Kim et al. 2014; Klockow-McClain et al. 2020; Morss et al. 2010; Hohle, and Teigen 2015; Løhre 2018; Windschitl and Weber 1999), motivated reasoning (Dieckmann et al. 2017), and numeracy (Kong et al. 1986; Bramwell et al. 2006; Harris et al. 2013; Rinne and Mazzocco 2013; Juanchich and Sirota 2016). Forecasters play a critical role in setting the context for communicating probability information through their use of language (Connelly and Knurth 1998; Franic and Pathak 2000; Kox et al. 2015; Pappenberger et al. 2013). The way in which forecasters frame messages can influence how audiences interpret risks (Harris et al. 2009; Keller et al. 2006; Wilson et al. 2019). 